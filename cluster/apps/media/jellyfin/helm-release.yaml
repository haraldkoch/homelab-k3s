---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: &app jellyfin
  namespace: media
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 0.2.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  install:
    createNamespace: true
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  dependsOn:
    - name: intel-gpu-plugin
      namespace: system
    - name: node-feature-discovery
      namespace: system
  values:
    image:
      repository: ghcr.io/onedr0p/jellyfin
      tag: 10.8.7@sha256:09d1822b3d925a92cd1d14d83fb77f185ffca632d193ba2200f76b6af107c3f4
    env:
      TZ: "${TIMEZONE}"
    service:
      main:
        type: LoadBalancer
        externalIPs: ["${SVC_JELLYFIN_ADDR}"]
        externalTrafficPolicy: Local
        ports:
          http:
            port: 8096
    ingress:
      main:
        enabled: true
        ingressClassName: nginx
        annotations:
          external-dns.home.arpa/enabled: "true"
          hajimari.io/enable: "true"
          hajimari.io/icon: "television-classic"
        hosts:
          - host: &host "{{ .Release.Name }}.${SECRET_PUBLIC_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - *host
            secretName: tls.jellyfin
      internal:
        enabled: true
        ingressClassName: nginx
        hosts:
          - host: &ihost "{{ .Release.Name }}.${SECRET_INTERNAL_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - *ihost
    podSecurityContext:
      runAsUser: 2000
      runAsGroup: 2000
      fsGroup: 2000
      fsGroupChangePolicy: "OnRootMismatch"
      supplementalGroups:
        - 44
        - 109
        - 100
    persistence:
      config:
        enabled: true
        existingClaim: jellyfin-config-v1
      media:
        enabled: true
        existingClaim: media-nfs
        mountPath: /media
      transcode:
        enabled: true
        type: emptyDir
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: feature.node.kubernetes.io/custom-intel-gpu
                  operator: In
                  values:
                    - "true"
    resources:
      requests:
        gpu.intel.com/i915: 1
        cpu: 100m
        memory: 1000Mi
      limits:
        gpu.intel.com/i915: 1
        memory: 6000Mi
