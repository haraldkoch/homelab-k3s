---
version: "3"

vars:
  TIMENOW:
    sh: date +%Y%m%d-%H%M%S
tasks:

  verify:
    desc: Verify flux meets the prerequisites
    cmds:
      - flux check --pre

  install:
    desc: Install Flux into your cluster
    cmds:
      - kubectl apply --kustomize {{.KUBERNETES_DIR}}/bootstrap
      - cat {{.SOPS_AGE_KEY_FILE}} | kubectl -n flux-system create secret generic sops-age --from-file=age.agekey=/dev/stdin
      - sops --decrypt {{.KUBERNETES_DIR}}/flux/vars/cluster-secrets.sops.yaml | kubectl apply -f -
      - kubectl apply -f {{.KUBERNETES_DIR}}/flux/vars/cluster-settings.yaml
      - kubectl apply --kustomize {{.KUBERNETES_DIR}}/flux/config
    preconditions:
      - sh: test -f {{.SOPS_AGE_KEY_FILE}}
        msg: |
          Age key file is not found. Did you forget to create it?
    vars:
      SOPS_AGE_KEY_FILE: ~/.config/sops/age/keys.txt

  reconcile:
    desc: Force update Flux to pull in changes from your Git repository
    cmds:
      - flux reconcile -n flux-system source git home-kubernetes
      - flux reconcile -n flux-system kustomization cluster

  list-dockerhub:
    desc: What dockerhub images are running in my cluster
    cmds:
      - kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{'\n'}{range .spec.containers[*]}{.image}{'\n'}{end}{end}" | sort | uniq | grep -Ev 'quay|gcr|ghcr|ecr|us-docker|registry.k8s' | grep -Ev 'bitnami|rook|intel|grafana' |  sed -e 's/docker\.io\///g' | sort | uniq

  delete-failed-pods:
    desc: Deletes failed pods
    cmds:
      - kubectl delete pods --field-selector status.phase=Failed -A --ignore-not-found=true

  delete-jobs:
    desc: Delete all jobs
    cmds:
      - kubectl delete job -A --all

  hr-restart:
    desc: Restart all failed Helm Releases
    cmds:
      - kubectl get hr --all-namespaces | grep False | awk '{print $2, $1}' | xargs -l bash -c 'flux suspend hr $0 -n $1'
      - kubectl get hr --all-namespaces | grep False | awk '{print $2, $1}' | xargs -l bash -c 'flux resume hr $0 -n $1'

  wait-pod-pending:
    aliases: [waitp]
    internal: true
    desc: Wait for a job's pod to change its status to pending
    vars:
      NAME: '{{ or .NAME (fail "Missing `NAME` environment variable!") }}'
      NS: '{{ .NS | default "default" }}'
    cmds:
      - until [[ $(kubectl -n "{{.NS}}" get pod "{{.NAME}}" -o jsonpath='{.items[*].status.phase}') == "Pending" ]]; do sleep 1; done

  wait-pod-running:
    aliases: [waitp]
    internal: true
    desc: Wait for a job's pod to change its status to pending
    vars:
      NAME: '{{ or .NAME (fail "Missing `NAME` environment variable!") }}'
      NS: '{{ .NS | default "default" }}'
    cmds:
      - until [[ $(kubectl -n "{{.NS}}" get pod "{{.NAME}}" -o jsonpath='{.items[*].status.phase}') == "Running" ]]; do sleep 1; done

  wait-finish:
    internal: true
    desc: Wait for a job's pod to change its status to pending
    vars:
      NAME: '{{ or .NAME (fail "Missing `NAME` environment variable!") }}'
      NS: '{{ .NS | default "default" }}'
      # TYPE: '{{ .TYPE | default "job" }}'
      # WAIT_ARGS: '{{.WAIT_ARGS | default "echo \"{{.NAME}} is still running, logs:\" && kubectl -n {{.NS}} logs {{.NAME}} --since 2s -f;"}}'
    cmds:
      - |-
        until kubectl -n {{.NS}} wait {{.NAME}} --for condition=complete --timeout=2s; do
          echo "{{.NAME}} is still running, logs:" && kubectl -n {{.NS}} logs {{.NAME}} --since 2s -f || true;
        done

  iperf2:
    desc: Start a iperf2 server on node SERVER_NODE, and iperf2 client on node CLIENT_NODE, to benchmark network performance.
    dir: "{{.ROOT_DIR}}/.taskfiles/Cluster/iperf2"
    vars: &iperf2-vars
      SERVER_NAME: &iperf2-server-name 'iperf2-server-{{- .TIMENOW -}}'
      SERVER_NS: &iperf2-server-ns '{{ .SERVER_NS | default "default" }}'
      CLIENT_NAME: &iperf2-client-name 'iperf2-client-{{- .TIMENOW -}}'
      CLIENT_NS: &iperf2-client-ns '{{ .CLIENT_NS | default "default" }}'
      CLUSTER_DOMAIN: '{{ .CLUSTER_DOMAIN | default "cluster.local" }}'
      SERVER_PORT: '{{ .SERVER_PORT | default "5001" }}'
      SERVER_NODE: '{{ or .SERVER_NODE (fail "Missing `SERVER_NODE` environment variable!") }}'
      CLIENT_NODE: '{{ or .CLIENT_NODE (fail "Missing `CLIENT_NODE` environment variable!") }}'
      SERVER_ARGS: '{{ .SERVER_ARGS | default "" }}'
      CLIENT_ARGS: '{{ .CLIENT_ARGS | default "" }}'
    env: *iperf2-vars
    cmds:
      - cat ./ServerJob.tmpl.yaml | envsubst | kubectl apply -f -
      - defer: cat ./ServerJob.tmpl.yaml | envsubst | kubectl delete -f -
      - task: wait-pod-running
        vars:
          NAME: '-l job-name={{.SERVER_NAME}}'
          NS: '{{.SERVER_NS}}'
      - cat ./ClientJob.tmpl.yaml | envsubst | kubectl apply -f -
      - defer: cat ./ClientJob.tmpl.yaml | envsubst | kubectl delete -f -
      - task: wait-finish
        vars:
          NAME: 'jobs/{{.CLIENT_NAME}}'
          NS: '{{.CLIENT_NS}}'
